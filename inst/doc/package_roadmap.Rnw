\documentclass{article}
\title{Notes on using \texttt{enzalyze}}
\author{Andrew D. Steen}

\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle


\section{3 March 2014 notes}
Plan:
\begin{itemize}
\item Read in raw data using \texttt{read\_x} (at first, all I have is \texttt{read\_biotek}, which is really just `read wide format data with sample info encoded in column names)
\item
\end{itemize}


\section{Introduction}

My idea for the workflow for this package is:

\begin{enumerate}
  \item \textbf{Read} in the export file using the appropriate read function. Right now the only function I have is \texttt{read\_biotek}. Note that I have no real idea what the Biotek raw format actually looks like - this is basically a guess. Melt it by well location.
  \item \textbf{Preprocess} the data:
  \begin{enumerate}
    \item Read \& parse the `legend file' that contains the name of each sample in each well. Reading is done by \texttt{read\_plate\_setup()} and parsing is done by \texttt{sample\_name\_parser()}.
    \item Merge the raw data object and the `legend' object. 
    \item \textit{I thought I was going to put something else there}
  \end{enumerate}
  \item \textbf{Calculate} calibration curves.
    \begin{enumerate}
      \item Pull out the standards from the parsed, merged data frame
      \item For each standard name (\& sample/buffer?) calculate a calibration curve. Return the slopes etc. To somewhere.
    \end{enumerate}
    \item \textbf{Calibrate} the data.
\end{enumerate}




\end{document}